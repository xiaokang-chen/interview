# 面试题汇总

[toc]

## 一、Golang

## 二、MySQL

### 2,1 MySQL事务4大特性的理解

### 2.2 并行事务可能出现什么问题

MySQL服务端允许多个客户端连接，意味着 MySQL 会出现同时处理多个事务的情况。那么在同时处理多个事务的时候，就可能出现脏读、不可重复读、幻读的问题。

1. 脏读
一个事务「读到」了另一个「未提交事务修改过的数据」；
A 更新数据后，进行`回滚`，B在回滚前读了数据，数据和回滚后的数据不相同。
2. 不可重复读
一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况；
B 更新数据，导致A在更新操作前读取的数据和更新操作后读取的数据不一致。
3. 幻读
一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况；
A插入一条记录，B在插入操作前和插入操作后条件查询得出的数据数量不一致。

严重性：脏读 > 不可重复读 > 幻读

事务隔离级别：

1. 读未提交
2. 读已提交
3. 可重复读
4. 串行化

## 三、Redis

### 3.1 如何用redis实现分布式锁？有什么弊端，用什么方案替代

![redis分布式锁](/pic/redis分布式锁.jpg)

```shell
SET lock_key unique_value NX PX 10000
```

基于redis分布式锁的实现过程：

1. 上锁：包括读取锁变量、检查锁变量值和设置锁变量值三个操作，需要满足原子性操作，所以使用SET命令带上NX来实现加锁；锁变量需要设置过期时间，避免客户端拿到锁之后发生异常，导致锁一直无法释放；锁变量的值需要区分来自不同客户端的加锁操作，避免释放锁时，出现误释放操作；
2. 解锁：解锁过程就是将lock_key键删除，要保证执行操作的客户端就是加锁的客户端，所以解锁的时候，需要先判断锁的unique_value是否为加锁客户端，是的话，才将key删除；

优点：性能高效、实现方便，对于集群部署来说可避免单点故障；
缺点：Redis主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性；

**Redis+Lua：**
利用Redis+Lua实现操作的原子性，一段复杂的业务逻辑，可以通过封装在Lua脚本中发送给Redis，保证这段复杂业务逻辑执行的原子性。

**看门狗：**
通过`setex`实现，如果锁达到了超时时间，但业务代码还没执行完，可以通过看门狗机制定时（比如每隔10s）刷新lock_key的过期时间，来保证锁的时间续期；

<font color='red'>说起分布式的概念，首当其冲就是CAP理论，即满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）。但是CAP理论告诉我们，任何系统只能满足其中两个。</font>

如果你的实际业务场景，更需要的是保证数据一致性。那么请使用CP类型的分布式锁，比如：zookeeper；
如果你的实际业务场景，更需要的是保证数据高可用性。那么请使用AP类型的分布式锁，比如：redis；

## 四、操作系统

### 4.1 select和epoll的区别

1. 单个进程能够监视的文件描述符数量
select支持的`文件描述符（fd）`默认只有1024；
epoll文件描述符无上限；
2. I/O多路复用机制
select只能知道有I/O事件发生，却并不知道是哪几个流，只能无差别轮询；
epoll基于事件驱动，只关心“活跃”链接，无需遍历全部文件描述符；

### 4.2 一致性Hash，场景、解决的问题

<font color='red'>背景：解决【负载均衡】问题</font>
大多数网站背后肯定不是只有一台服务器提供服务，因为单机的并发量和数据量都是有限的，所以都会用多台服务器构成集群来对外提供服务。但是问题来了，现在有那么多个节点（后面统称服务器为节点，因为少一个字），要如何分配客户端的请求呢？

不同的负载均衡算法适用的业务场景也不同的。

轮询这类的策略只能适用与每个节点的数据都是相同的场景，访问任意节点都能请求到数据。但是不适用分布式系统，因为分布式系统意味着数据水平切分到了不同的节点上，访问数据的时候，一定要寻址存储该数据的节点。

哈希算法虽然能建立数据和节点的映射关系，但是每次在节点数量发生变化的时候，最坏情况下所有数据都需要迁移，这样太麻烦了，所以不适用节点数量变化的场景。

为了减少迁移的数据量，就出现了一致性哈希算法。

一致性哈希是指将「存储节点」（**可以对节点IP做hash，对2^32取模**）和「数据」都映射到一个首尾相连的哈希环上，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。
当需要对指定 key 的值进行读写的时候，要通过下面 2 步进行寻址：

- 首先，对 key 进行哈希计算，确定此 key 在环上的位置；
- 然后，从这个位置沿着顺时针方向走，遇到的第一节点就是存储 key 的节点

但是一致性哈希算法不能够均匀的分布节点，会出现大量请求都集中在一个节点的情况，在这种情况下进行容灾与扩容时，容易出现雪崩的连锁反应。

为了解决一致性哈希算法不能够均匀的分布节点的问题，就需要引入虚拟节点，对一个真实节点做多个副本。不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。（ **Nginx 的一致性哈希算法，每个权重为 1 的真实节点就含有160 个虚拟节点**）

引入虚拟节点后，可以提高节点的均衡度，还会提高系统的稳定性。所以，带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景，而且适合节点规模会发生变化的场景。

### 4.3 零拷贝技术实现原理，解决什么问题？

<font color='red'>背景：减少文件读写、网络通信、数据库操作中数据拷贝和上下文切换次数</font>

零拷贝的原理是利用虚拟内存和DMA技术。

DMA：**直接内存访问**。在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务。

具体场景：从一个文件中读出数据并将数据传到另一台服务器上：

```c
// 伪码
read(file, tmp_buf, len);
write(socket, tmp_buf, len);
```

![零拷贝1](/pic/零拷贝1.jpg)

期间共发生了`4次用户态与内核态的上下文切换`，因为发生了两次系统调用，一次是 read() ，一次是 write()，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。其次，还发生了`4次数据拷贝`，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的。

## 五、计算机网络

## 六、算法

## 七、项目经验
