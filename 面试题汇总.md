# 面试题汇总

[toc]

## 一、Golang

## 二、MySQL

### 2,1 MySQL事务4大特性的理解

### 2.2 并行事务可能出现什么问题

MySQL服务端允许多个客户端连接，意味着 MySQL 会出现同时处理多个事务的情况。那么在同时处理多个事务的时候，就可能出现脏读、不可重复读、幻读的问题。

1. 脏读
一个事务「读到」了另一个「未提交事务修改过的数据」；
A 更新数据后，进行`回滚`，B在回滚前读了数据，数据和回滚后的数据不相同。
2. 不可重复读
一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况；
B 更新数据，导致A在更新操作前读取的数据和更新操作后读取的数据不一致。
3. 幻读
一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况；
A插入一条记录，B在插入操作前和插入操作后条件查询得出的数据数量不一致。

严重性：脏读 > 不可重复读 > 幻读

事务隔离级别：

1. 读未提交
2. 读已提交
3. 可重复读
4. 串行化

### 2.3 乐观锁和悲观锁

1. 乐观锁：
它假设事务之间的冲突很少发生，因此不主动对数据进行加锁。乐观锁的实现方式通常使用数据版本号或时间戳。Redis实现的是一种乐观锁机制（通过watch）。

2. 悲观锁：
它假设事务之间的冲突经常发生，因此采取主动加锁来保证事务的安全性。在MySQL中，悲观锁可以分为行锁和表锁两种类型。
各种行锁和表锁的类型和模式，用于精细控制对数据的访问权限。

## 三、Redis

### 3.1 如何用redis实现分布式锁？有什么弊端，用什么方案替代

![redis分布式锁](/pic/redis分布式锁.jpg)

```shell
SET lock_key unique_value NX PX 10000
```

基于redis分布式锁的实现过程：

1. 上锁：包括读取锁变量、检查锁变量值和设置锁变量值三个操作，需要满足原子性操作，所以使用SET命令带上NX来实现加锁；锁变量需要设置过期时间，避免客户端拿到锁之后发生异常，导致锁一直无法释放；锁变量的值需要区分来自不同客户端的加锁操作，避免释放锁时，出现误释放操作；
2. 解锁：解锁过程就是将lock_key键删除，要保证执行操作的客户端就是加锁的客户端，所以解锁的时候，需要先判断锁的unique_value是否为加锁客户端，是的话，才将key删除；

优点：性能高效、实现方便，对于集群部署来说可避免单点故障；
缺点：Redis主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性；

**Redis+Lua：**
利用Redis+Lua实现操作的原子性，一段复杂的业务逻辑，可以通过封装在Lua脚本中发送给Redis，保证这段复杂业务逻辑执行的原子性。

**看门狗：**
通过`setex`实现，如果锁达到了超时时间，但业务代码还没执行完，可以通过看门狗机制定时（比如每隔10s）刷新lock_key的过期时间，来保证锁的时间续期；

<font color='red'>说起分布式的概念，首当其冲就是CAP理论，即满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）。但是CAP理论告诉我们，任何系统只能满足其中两个。</font>

如果你的实际业务场景，更需要的是保证数据一致性。那么请使用CP类型的分布式锁，比如：zookeeper；
如果你的实际业务场景，更需要的是保证数据高可用性。那么请使用AP类型的分布式锁，比如：redis；

### 3.2 Redis如何实现延迟队列

延迟队列是指把当前要做的事情，往后推迟一段时间再做，场景如下：

- 在电商平台下单，超过一定时间未付款，订单自动取消；
- 打车时，规定时间内没有车主接单，平台会取消你的单；
- 点外卖时，商家10分钟没有接单，平台会自动取消订单；

![redis延迟队列](/pic/redis延迟队列.jpg)

实现步骤：

1. 添加延迟任务

    ```shell
    # ZADD KEY_NAME SCORE1 VALUE1.. SCOREN VALUEN
    # 添加一个延迟任务task1，延迟时间为1000毫秒
    zadd delay_queue 1000 task1
    ```

2. 处理延迟任务
使用`zrangebysocre`查询符合条件的所有待处理任务，通过循环处理任务，一般来说处理延迟任务需要通过lua脚本实现：

    ```lua
    local tasks = redis.call('ZRANGEBYSCORE', KEYS[1], '-inf', ARGV[1])
    if #tasks > 0 then
        redis.call('ZREMRANGEBYSCORE', KEYS[1], '-inf', ARGV[1])
        for i, task in ipairs(tasks) do
            redis.call('LPUSH', KEYS[2], task)
        end
    end
    ```

### 3.3 Redis大Key如何处理

大 key 并不是指 key 的值很大，而是 key 对应的 value 很大。
大 Key 会带来以下4种影响：

- 客户端超时阻塞：因为操作的耗时，导致客户端等待；
- 服务端阻塞：阻塞redis工作线程；
- 网络阻塞：大Key在网络传输消耗带宽
- 内存节点不均：

**如何删除？**
使用异步删除`unlink`，可以做到不阻塞redis工作线程去删除大key。

### 3.4 Redis的事务与Lua脚本

Redis可以通过使用`MULTI`开启事务和`EXEC`执行事务，Redis的事务就是一个命令队列，并不是完全意义上关系型数据库中事务的概念，可以通过`WATCH`进行事务“加乐观锁”，乐观锁就是信任其他人不会修改数据，如果发生了修改，自己就不更新了。

```shell
# 客户端1
> WATCH a
OK
# 通过MULTI开始事务队列
> MULTI
OK
(TX)> INCR a
QUEUED

# 客户端2
> SET a 111

# 客户端1
(TX)> EXEC
(nil)
> GET a
"111"
```

Redis事务不具备原子性，队列中的命令不会`全部成功`或`全部失败`。

```shell
# 客户端1
> MULTI
OK
(TX)> INCR a
# 错误命令
(TX)>  SET a dsd ds 12
QUEUED
(TX)> EXEC
1) (integer) 112
2) (error) ERR syntax error
> GET a
"112"
```

**Lua脚本：**
Redis可以使用lua脚本来实现传统意义上的事务（实现原子性）。它是是通过`EVAL`命令实现的：

```shell
# 显示值（不执行）
EVAL "return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}" 2 a b 111 222

# 执行命令
EVAL "redis.call('set', KEYS[1], ARGV[1]);return 'ok'" 1 a 111
```

也可以通过`redis-cli --eval`去加载一个外部指定的`.lua`文件去执行：

1. vim创建一个.lua脚本，内容为：

    ```shell
    return redis.call('get', 'a')
    ```

2. 保存lua脚本，使用如下命令执行：

```shell
% redis-cli --eval get.lua
"1234"
```

### 2.1 事务的特性理解

### 2.2 分库分表

### 3.1 Redis Zset

## 四、操作系统

### 4.1 select和epoll的区别

1. 单个进程能够监视的文件描述符数量
select支持的`文件描述符（fd）`默认只有1024；
epoll文件描述符无上限；
2. I/O多路复用机制
select只能知道有I/O事件发生，却并不知道是哪几个流，只能无差别轮询；
epoll基于事件驱动，只关心“活跃”链接，无需遍历全部文件描述符；

epoll在go中的使用：net/http库（基于注册的事件循环）

### 4.2 一致性Hash，场景、解决的问题

<font color='red'>背景：解决【负载均衡】问题</font>
大多数网站背后肯定不是只有一台服务器提供服务，因为单机的并发量和数据量都是有限的，所以都会用多台服务器构成集群来对外提供服务。但是问题来了，现在有那么多个节点（后面统称服务器为节点，因为少一个字），要如何分配客户端的请求呢？

不同的负载均衡算法适用的业务场景也不同的。

轮询这类的策略只能适用与每个节点的数据都是相同的场景，访问任意节点都能请求到数据。但是不适用分布式系统，因为分布式系统意味着数据水平切分到了不同的节点上，访问数据的时候，一定要寻址存储该数据的节点。

哈希算法虽然能建立数据和节点的映射关系，但是每次在节点数量发生变化的时候，最坏情况下所有数据都需要迁移，这样太麻烦了，所以不适用节点数量变化的场景。

为了减少迁移的数据量，就出现了一致性哈希算法。

一致性哈希是指将「存储节点」（**可以对节点IP做hash，对2^32取模**）和「数据」都映射到一个首尾相连的哈希环上，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。
当需要对指定 key 的值进行读写的时候，要通过下面 2 步进行寻址：

- 首先，对 key 进行哈希计算，确定此 key 在环上的位置；
- 然后，从这个位置沿着顺时针方向走，遇到的第一节点就是存储 key 的节点

但是一致性哈希算法不能够均匀的分布节点，会出现大量请求都集中在一个节点的情况，在这种情况下进行容灾与扩容时，容易出现雪崩的连锁反应。

为了解决一致性哈希算法不能够均匀的分布节点的问题，就需要引入虚拟节点，对一个真实节点做多个副本。不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。（ **Nginx 的一致性哈希算法，每个权重为 1 的真实节点就含有160 个虚拟节点**）

引入虚拟节点后，可以提高节点的均衡度，还会提高系统的稳定性。所以，带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景，而且适合节点规模会发生变化的场景。

### 4.3 零拷贝技术实现原理，解决什么问题？

<font color='red'>背景：减少文件读写、网络通信、数据库操作中数据拷贝和上下文切换次数</font>

零拷贝的原理是利用虚拟内存和DMA技术。

DMA：**直接内存访问**。在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务。

具体场景：从一个文件中读出数据并将数据传到另一台服务器上：

```c
// 伪码
read(file, tmp_buf, len);
write(socket, tmp_buf, len);
```

![零拷贝1](/pic/零拷贝1.jpg)

期间共发生了`4次用户态与内核态的上下文切换`，因为发生了两次系统调用，一次是 read() ，一次是 write()，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。其次，还发生了`4次数据拷贝`，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的。

零拷贝实现：

有两种方式：
（1）mmap + write；
（2）sendfile；

```c

```

## 五、计算机网络

## 六、算法

## 七、项目经验

### 7.1 基于redis分布式锁概念，说说其他的分布式锁
