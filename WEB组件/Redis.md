# Redis

![redis八股文提纲](/pic/redis八股文提纲.webp)
[toc]

## 一、Redis数据类型和数据结构

![Redis数据类型和数据结构](/pic/redis数据结构.jpg)

参考：<https://xiaolincoding.com/redis/data_struct/data_struct.html>

### 1.1 ziplist

**zipist数据结构如下**：
![ziplist](/pic/ziplist.jpg)

压缩列表节点包括三部分：

- prevlen
记录了「前一个节点」的长度，目的是为了实现从后向前遍历；
- encoding
记录了当前节点实际数据的「类型和长度」，类型主要有两种：字符串和整数；
- data
记录了当前节点的实际数据，类型和长度都由 encoding 决定；

1. ziplistNode保存prevlen的目的
为了实现节点从后往前遍历，后面listpack保存len也是为了
相同目的。

### 1.2 quicklist

quicklist其实就是【双向链表+压缩列表】的组合，因为quicklist本身是个列表，而链表中的每个元素又是一个压缩列表。

1. 压缩列表的弊端
会出现【连锁更新】的风险
2. quicklist解决办法
通过控制每个链表节点中压缩列表的大小或元素个数，来规避
连锁更新带来的影响。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能。

**quicklist数据结构如下**：
![quicklist](/pic/quicklist.jpg)

### 1.3 listpack

quicklist减少了【连锁更新】造成的影响，但是并没有完全解决这一问题，这源于ziplist的底层设计结构。要想彻底解决这个问题，需要设计一个新的数据结构。redis7.0已经将所有使用zipist数据结构的对象全部替换为listpack。

**listpack数据结构如下**：
![listpack](/pic/listpack.jpg)

listpack节点包括三部分：

1. encoding
记录了当前节点实际数据的「类型和长度」，类型主要有两种：字符串和整数；
2. data
记录了当前节点的实际数据，类型和长度都由 encoding 决定；
3. len
encoding+data的总长度；

<font color='red'>相比于ziplist，listpack不再记录前一个加点长度字段，只记录当前节点长度。当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题。</font>

### 1.4 zskiplist

**quicklist（跳表）数据结构如下**：
![zskiplist跳表](/pic/zskiplist.jpg)

数据量很大时，跳表的查找复杂度为O(logN)

1. 跳表节点层数设置
  跳表在创建节点的时候，随机生成每个节点的层数（层高最大为：redis5.0位64，redis7.0为32）。

## 二、Redis数据持久化

### 2.1 redis数据持久化方式

#### 2.1.1 AOF日志

每执行一条`写操作`命令，就把该命令以追加的方式写入到一个文件里。重启 Redis 的时候，先去读取这个文件里的命令，并且执行它，就会恢复缓存数据。
`AOF日志是在主线程中执行的`

AOF写回策略如下：
![AOF写回策略](/pic/AOF写回策略.jpg)

AOF日志过大会触发`AOF重写机制`，通过重写机制，删除被覆盖的旧命令，如：

```shell
set name xk
set name xkchen
```

上述两个命令在重写时就会变成`set name xkchen`。这样一来，一个键值对在重写日志中只用一条命令就行了。

#### 2.1.2 RDB快照

将某一时刻的内存数据，以`二进制`的方式写入磁盘；redis的快照是`全量快照`，每次执行快照，是将内存中所有数据都记录到磁盘中。

**RDB快照缺点：**
当服务器发生故障时，丢失的数据会比AOF更多。因为是全量快照，所以频率不能太高，否则会影响redis性能，而AOF可以秒级的方式记录数据。

Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行：

- 执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，会阻塞主线程；
- 执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以避免主线程的阻塞；

#### 2.1.3. 混合持久化

开启方式：

```shell
aof-use-rdb-preamble yes
```

集成AOF和RDB的优点；

混合持久化工作在 <font color='red'>AOF 日志重写过程</font>

使用混合持久化，AOF文件的前半部分是RDB格式的全量数据，后半部分是AOF的增量命令数据。这样做的好处：

1. 由于前半部分是 RDB 内容，这样加载的时候速度会很快
2. 加载完 RDB 的内容后，才会加载后半部分的 AOF 内容
![redis混合持久化](/pic/redis混合持久化.jpg)

### 2.2 如何避免大key

1. 大key带来的影响

   - 客户端阻塞：由于redis单线程，在操作大key会比较耗时，客户端需要等待很久
   - 服务端阻塞：使用del命令，会阻塞工作线程
   - 引发网络阻塞：如果单个Key大小1M，每秒来1000次访问，那么就会产生1000M流量，对于普通千兆网卡服务器是灾难性的
   - 内存分布不均：集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大

2. 如何避免大key
在设计阶段，就把大key拆分成小key。或者定期检查redis是否存在大key，如果可以删除，使用unlink代替del命令，防止阻塞主线程。

## 三、Redis集群高可用

### 3.1 主从复制

主从复制可以保证多台服务器的数据一致性，且主从服务器之间采用的是「读写分离」的方式。

主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来的写操作命令，然后执行这条命令，如下图：
![redis集群读写分离](/pic/redis集群读写分离.png)

#### 第一次同步（全量复制）

多台服务器之间通过`第一次同步`确定主从关系，redis可以在想要被设置为从服务器的redis上使用`replicaof <主服务器ip> <主服务器redis端口号>`来实现。

主服务器的第一次同步如下：

1. 建立链接，协商同步；
2. 主服务器通过`bgsave`生成RDB文件，并传给从服务器，从服务器载入数据文件；
3. 主服务器发送写命令（存在于replication buffer）给从服务器，从服务器进行数据同步；
![redis集群第一次同步](/pic/redis集群第一次同步.png)

#### 命令传播

主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接。后续主服务器可以通过这个连接继续将写操作命令传播给从服务器，然后从服务器执行该命令，使得与主服务器的数据库状态相同。这个过程叫做**基于长连接的命令传播**。

#### 分摊主服务器压力

主服务器是可以有多个从服务器的，如果从服务器数量非常多，而且都与主服务器进行全量同步的话，就会带来两个问题：

1. 如果主服务器内存过大，执行创建后台进程是会阻塞主线程的，从而影响redis正常处理请求；
2. 传输 RDB 文件会占用主服务器的网络带宽，会对主服务器响应命令请求产生影响；

解决方法：设置从服务器中间层B，服务器B可以作为其他从服务器（如C、D、E...）的“主服务器”，而B是A的从服务器。

#### 增量复制

如果主从服务器间的网络连接断开了，那么就无法进行命令传播了，这时从服务器的数据就没办法和主服务器保持一致了，客户端就可能从「从服务器」读到旧的数据。
如果此时断开的网络，又恢复正常了，要怎么继续保证主从服务器的数据一致性呢？
![redis集群增量复制](/pic/redis集群增量复制.png)

那么关键的问题来了，主服务器怎么知道要将哪些增量数据发送给从服务器呢？

在主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入到 repl_backlog_buffer 缓冲区里，因此 这个缓冲区里会保存着最近传播的写命令。

#### 总结

主从复制共有三种模式：`全量复制`、`基于长连接的命令传播`、`增量复制`。

主从服务器第一次同步的时候，就是采用`全量复制`，此时主服务器会两个耗时的地方，分别是生成 RDB 文件和传输 RDB 文件。为了避免过多的从服务器和主服务器进行全量复制，可以把一部分从服务器升级为「经理角色」，让它也有自己的从服务器，通过这样可以分摊主服务器的压力。

第一次同步完成后，主从服务器都会维护着一个长连接，主服务器在接收到写操作命令后，就会通过这个`基于长连接的命令传播`给从服务器写命令，来保证主从服务器的数据一致性。

如果遇到网络断开，`增量复制`就可以上场了

### 3.2 Redis哨兵机制（sentinel）

哨兵的作用是实现`主从节点故障转移`。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。sentinel机制下每个节点会持有全量数据，且数据保持一致，其解决的是**Redis高可用问题**。
哨兵要做的事情包括：

- 监控：哨兵每隔1s会给所有主从节点发送ping命令来进行心跳检测；
- 选主：将一个从节点选举为主节点；
- 通知：把新主节点的相关信息通知给从节点和客户端；

**监控：**

通常，为了防止误判，所以哨兵需要集群部署：
![redis集群哨兵](/pic/redis集群哨兵.png)

**选主：**

选主之前需要先确定究竟选哪个哨兵进行`主从节点切换`。
哨兵是集群部署，所以哨兵之间需要进行leader哨兵的选举，选举从候选者中诞生，候选者即是首先发现主节点【主观下线】，并根据其他哨兵投票，得到主节点【客观下线】结论。

**通知：**

哨兵集群以及通知客户端都是基于`发布/订阅模式`

### 3.3 Redis Cluster

![redis_cluster集群](/pic/redis_cluster集群.jpg)
Redis Cluster要求至少需要3个master才能组成一个集群，同时每个master至少需要有一个slave节点，各个节点之间保持TCP通信。当master发生了宕机， Redis Cluster自动会将对应的slave节点提拔为master，来重新对外提供服务。
采用去中心化结构，`每个节点保存部分数据以及整个集群的状态`，也即数据会分散到各个节点上。各个节点会相互通信，采用gossip协议交换节点元数据信息。
Redis Cluster解决的是**超大规模数据处理的问题**，同时提供高可用支持。

Redis Cluster 功能：负载均衡，故障切换，主从复制。

#### 3.3.1 负载均衡

redis cluster 使用哈希槽的方式分配key，具体如下：用crc16算法对key进行计算，得出的数值结果对16384（2^14，16K）取模，得到的结果落到对应负责区间的节点上。
`之所以选择16384的原因在于通常我们不会部署超过10000个redis主节点，因此16384就够用了`
![redis_cluster哈希槽](/pic/redis_cluster哈希槽.jpg)

集群间通信：一种是集中式，比如springcloud服务集群信息保存在配置中心；而redis使用的是gossip。gossip通信端口为redis监听端口+10000。Gossip消息可分为：

- meet：通知新节点加入；
- ping：检测节点状态；
- pong：接收到meet和ping时，作为相应消息返回；也可以向集群内使用pong广播通知自身状态的更新；
- fail：节点判断另外一个节点下线，会向集群广播一个fail消息，其他节点收到fail消息后把对应节点更新为下线状态；

#### 3.3.2 故障切换

当一个从节点发现自己正在复制的主节点进入了已下线状态时，从节点将开始对下线主节点进行故障转移，以下是故障转移执行的步骤：

- 从节点会执行`SLAVEOF no one`命令，成为新的主节点；
- 新的主节点会撤销所有对已下线主节点的槽指派，并将这些槽全部指派给自己；
- 新的主节点向集群广播一条PONG消息，这条PONG消息可以让集群中的其他节点立即知道这个节点已经由从节点变成了主节点，并且这个主节点已经接管了原本由已下线节点负责处理的槽。
- 新的主节点开始接收和自己负责处理的槽有关的命令请求，故障转移完成。

#### 3.3.3 主从复制

和上述3.1的主从复制过程一样

## 四、Redis缓存设计

### 4.1 缓存雪崩、击穿、穿透

![redis缓存异常](/pic/redis缓存异常.png)

### 4.2 数据库和缓存数据一致性

无论是「先更新数据库，再更新缓存」，还是「先更新缓存，再更新数据库」，这两个方案都存在并发问题，当两个请求并发更新同一条数据的时候，可能会出现缓存和数据库中的数据不一致的现象。
![redis先更新数据库](/pic/redis先更新数据库.png)
![redis先更新缓存](/pic/redis先更新缓存.png)

在「先更新数据库，再更新缓存」方案上，解决方法：
在更新缓存前先加个`分布式锁`。保证同一时间只运行一个请求更新缓存，就会不会产生并发问题了，当然引入了锁后，对于写入的性能就会带来影响。

**删除缓存方案：**
不更新缓存，而是删除缓存中的数据。然后，到读取数据时，发现缓存中没了数据之后，再从数据库中读取数据，更新到缓存中

相比于更新缓存来说，【删除缓存】利用系统设计中的`懒加载`思想，适用于“加载代价大”的操作。原因如下：

1. 缓存往往可能来源于多张表的聚合，更新可能会导致多表联查，这个操作非常耗时（而更新到数据库表中的数据往往仅仅就是一个表中的一个字段）。
2. 缓存数据也不一定是更新后立马会被读取。从计算资源和整体性能的考虑，更新的时候删除缓存，等到下次查询命中再填充缓存，是一个更好的方案。

第二步：【缓存删除】失败，怎么解决？
可以引入消息队列，将缓存更新的任务加入到消息队列中进行重试，如果重试后还出错，进行业务层面告警。

## 五、Redis过期删除策略和内存淘汰策略

### 5.1 过期删除策略

常见的三种过期删除策略：

1. 定时删除：在设置key过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器定时自动执行key的删除操作。
优点：对内存较好：保证过期key在第一时间删除；
缺点：对cpu不友好：当有大量过期key时，会占用相当一部分cpu时间；
2. 惰性删除：不主动删除过期key，每次访问key时，判断key是否过期，如果过期则删除key；
优点：每次访问时才删除key，对cpu友好；
缺点：如果一个key已经过期，而只要key不被访问，就一直占用着内存，对内存不友好；
3. 定期删除：每隔一段时间，从数据库中取出一定数量的key进行过期检查并删除过期key；
优点：通过限制删除操作执行的时长的频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。
缺点：难以确定删除操作执行的时长和频率。如果执行太频繁，会变得和定时删除策略一样；如果执行太少，就会和惰性删除一样；

**redis过期删除策略：**
单单使用上面的任何一种都无法满足实际需求。redis选择【惰性删除 + 定期删除】两种策略配合使用，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。

惰性删除自不必说，直接判断key是否过期，如果过期，则直接删除，并返回null给客户端；否则直接返回数据给客户端。
对于定期删除来说，需要确定两件事：`检查时间的时间间隔设置多长`以及`每次检查随机抽查的数量是多少`。
对于第一个问题：redis每秒默认会进行10次过期检查
对于第二个问题：redis每轮默认会选择20个Key判断是否过期，如果过期数量超过5个（20/4），也就是25%，则会继续再抽查25个，直到过期比例小于25%。

可以看到定期删除是一个循环的过程，如下图：
![redis过期删除策略](/pic/redis过期删除策略.png)

### 5.2 内存淘汰策略

前面说的过期删除策略，是删除已过期的 key，而当 Redis 的运行内存已经超过 Redis 设置的最大内存之后，则会使用内存淘汰策略删除符合条件的 key，以此来保障 Redis 高效的运行。

**redis内存淘汰策略有8种：**

1. 不淘汰任何数据
如果内存超过了maxmemory，直接报错out of memory（oom）

2. 淘汰设置了过期时间的key

   - ttl：优先淘汰更早过期的key
   - random：随机淘汰设置了过期时间的任意key
   - lru：淘汰最久未使用的设置了过期时间的key
   - lfu：淘汰最少使用的设置了过期时间的key

3. 淘汰所有范围的数据key
  
   - random：随机淘汰任意key
   - lru：淘汰最久未使用的key
   - lfu：淘汰最少使用的key

传统 LRU 算法的实现是基于「链表」结构，链表中的元素按照操作顺序从前往后排列，最新操作的键会被移动到表头，当需要内存淘汰时，只需要删除链表尾部的元素即可，因为链表尾部的元素就代表最久未被使用的元素。
LFU 算法是根据数据访问次数来淘汰数据的，它的核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。
